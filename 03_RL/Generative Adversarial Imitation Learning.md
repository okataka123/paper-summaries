# Generative Adversarial Imitation Learning

## Abstruct
専門家の行動例からポリシーを学習することを考えます。ただし、専門家とのインタラクションや報酬信号へのアクセスはありません。一つのアプローチとしては、逆強化学習を用いて専門家のコスト関数を復元し、そのコスト関数から強化学習によってポリシーを抽出する方法があります。しかし、このアプローチは間接的であり、処理に時間がかかる可能性があります。

そこで本研究では、まるで逆強化学習の後に強化学習を行ったかのように、データから直接ポリシーを抽出するための新しい一般的なフレームワークを提案します。我々は、このフレームワークのある実装が、模倣学習と生成的敵対ネットワーク（GAN）との類似性を引き出すことを示し、そこからモデルフリーな模倣学習アルゴリズムを導出します。このアルゴリズムは、大規模かつ高次元の環境において、複雑な行動の模倣において既存のモデルフリー手法を大きく上回る性能を示します。


(ですます調をやめる！)


## Introduction